1. `firecrawl_scrape` – Scrape a single webpage with advanced options for content extraction.

    - Show me the content of the page at `https://example.com`, extracting only the main content and returning it in markdown format.

2. `firecrawl_map` – Discover URLs from a starting point.

    - List all accessible links from `https://example.com` using both sitemap.xml and HTML link discovery.

3. `firecrawl_crawl` – Start an asynchronous crawl of multiple pages from a starting URL.

    - Crawl all pages starting from `https://example.com/docs`, with a maximum depth of 3, and extract only the main content.

4. `firecrawl_check_crawl_status` – Check the status of a crawl job.

    - Check the status of the crawl job with ID `abc123xyz`.

5. `firecrawl_search` – Search and retrieve content from web pages with optional scraping.

    - Search for "AI research papers" and return the first 5 results in markdown format.

6. `firecrawl_extract` – Extract structured information from web pages using LLM.

    - Extract the company name, founding year, and CEO from the page at `https://example.com/about`.

7. `firecrawl_deep_research` – Conduct deep research on a query using web crawling, search, and AI analysis.

    - Research the topic "Sustainable energy technologies" with a time limit of 5 minutes and analyze up to 20 URLs.

8. `firecrawl_generate_llmstxt` – Generate a standardized LLMs.txt file for a given URL.

    - Generate the LLMs.txt file for the website at `https://example.com` and analyze up to 10 pages.

